{"primaryContentSections":[{"kind":"declarations","declarations":[{"tokens":[{"text":"var","kind":"keyword"},{"kind":"text","text":" "},{"text":"temperature","kind":"identifier"},{"text":": ","kind":"text"},{"text":"Float","kind":"typeIdentifier","preciseIdentifier":"s:Sf"}],"platforms":["iOS"],"languages":["swift"]}]}],"sections":[],"kind":"symbol","variants":[{"traits":[{"interfaceLanguage":"swift"}],"paths":["\/documentation\/edgecore\/edgeclient\/ai\/model\/chatrequest\/temperature"]}],"identifier":{"interfaceLanguage":"swift","url":"doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore\/EdgeClient\/AI\/Model\/ChatRequest\/temperature"},"metadata":{"role":"symbol","externalID":"s:8EdgeCore0A6ClientC2AIV5ModelV11ChatRequestV11temperatureSfvp","modules":[{"name":"EdgeCore"}],"title":"temperature","fragments":[{"text":"var","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"temperature"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Float","preciseIdentifier":"s:Sf"}],"roleHeading":"Instance Property","symbolKind":"property"},"schemaVersion":{"major":0,"minor":3,"patch":0},"hierarchy":{"paths":[["doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore","doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore\/EdgeClient","doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore\/EdgeClient\/AI","doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore\/EdgeClient\/AI\/Model","doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore\/EdgeClient\/AI\/Model\/ChatRequest"]]},"abstract":[{"text":"The temperature setting for AI models controls the level of randomness in the generated responses. A lower temperature (e.g., 0.1) makes the output more deterministic, prioritizing predictable or common responses. A higher temperature (e.g., 1.0) increases randomness, resulting in more diverse and creative answers. The default value is 0.1.","type":"text"}],"references":{"doc://com.mimik.EdgeCore/documentation/EdgeCore/EdgeClient/AI/Model/ChatRequest":{"abstract":[{"text":"For real-time interaction with an AI model. Optionally, use the context parameter to provide additional information for more relevant outputs, and adjust the temperature through the config parameter to control response creativity and randomness.","type":"text"}],"title":"EdgeClient.AI.Model.ChatRequest","navigatorTitle":[{"kind":"identifier","text":"ChatRequest"}],"identifier":"doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore\/EdgeClient\/AI\/Model\/ChatRequest","fragments":[{"kind":"keyword","text":"struct"},{"kind":"text","text":" "},{"kind":"identifier","text":"ChatRequest"}],"type":"topic","role":"symbol","kind":"symbol","url":"\/documentation\/edgecore\/edgeclient\/ai\/model\/chatrequest"},"https://www.mimik.com":{"titleInlineContent":[{"type":"text","text":"mimik"}],"type":"link","title":"mimik","identifier":"https:\/\/www.mimik.com","url":"https:\/\/www.mimik.com"},"doc://com.mimik.EdgeCore/documentation/EdgeCore/EdgeClient/AI":{"role":"symbol","kind":"symbol","title":"EdgeClient.AI","abstract":[{"text":"mimik, a pioneer in Hybrid Edge Cloud Computing, is thrilled to announce the launch of mimik ai, a groundbreaking universal operating environment that accelerates the integration of intelligent agents into solutions by bringing advanced capabilities directly to endpoint devices and computing nodes. mimik ai allows AI agents to run on any computing node, enabling them to discover, interact, and collaborate seamlesslyâ€”offline-first, with support for multi-cloud and multi-LLM environments. For more information go to ","type":"text"},{"identifier":"https:\/\/www.mimik.com","isActive":true,"type":"reference"}],"identifier":"doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore\/EdgeClient\/AI","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"AI","kind":"identifier"}],"navigatorTitle":[{"text":"AI","kind":"identifier"}],"url":"\/documentation\/edgecore\/edgeclient\/ai","type":"topic"},"doc://com.mimik.EdgeCore/documentation/EdgeCore/EdgeClient/AI/Model/ChatRequest/temperature":{"url":"\/documentation\/edgecore\/edgeclient\/ai\/model\/chatrequest\/temperature","kind":"symbol","role":"symbol","type":"topic","title":"temperature","abstract":[{"type":"text","text":"The temperature setting for AI models controls the level of randomness in the generated responses. A lower temperature (e.g., 0.1) makes the output more deterministic, prioritizing predictable or common responses. A higher temperature (e.g., 1.0) increases randomness, resulting in more diverse and creative answers. The default value is 0.1."}],"identifier":"doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore\/EdgeClient\/AI\/Model\/ChatRequest\/temperature","fragments":[{"text":"var","kind":"keyword"},{"kind":"text","text":" "},{"kind":"identifier","text":"temperature"},{"kind":"text","text":": "},{"kind":"typeIdentifier","text":"Float","preciseIdentifier":"s:Sf"}]},"doc://com.mimik.EdgeCore/documentation/EdgeCore":{"role":"collection","type":"topic","url":"\/documentation\/edgecore","identifier":"doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore","kind":"symbol","title":"EdgeCore","abstract":[]},"doc://com.mimik.EdgeCore/documentation/EdgeCore/EdgeClient":{"title":"EdgeClient","fragments":[{"text":"class","kind":"keyword"},{"text":" ","kind":"text"},{"kind":"identifier","text":"EdgeClient"}],"navigatorTitle":[{"kind":"identifier","text":"EdgeClient"}],"abstract":[{"type":"codeVoice","code":"EdgeClient"},{"type":"text","text":" is the main class of the "},{"type":"strong","inlineContent":[{"type":"text","text":"mimik Client Library"}]},{"text":".","type":"text"}],"kind":"symbol","role":"symbol","url":"\/documentation\/edgecore\/edgeclient","identifier":"doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore\/EdgeClient","type":"topic"},"doc://com.mimik.EdgeCore/documentation/EdgeCore/EdgeClient/AI/Model":{"navigatorTitle":[{"text":"Model","kind":"identifier"}],"abstract":[{"type":"text","text":"AI model."}],"role":"symbol","identifier":"doc:\/\/com.mimik.EdgeCore\/documentation\/EdgeCore\/EdgeClient\/AI\/Model","kind":"symbol","url":"\/documentation\/edgecore\/edgeclient\/ai\/model","title":"EdgeClient.AI.Model","fragments":[{"text":"struct","kind":"keyword"},{"text":" ","kind":"text"},{"text":"Model","kind":"identifier"}],"type":"topic"}}}